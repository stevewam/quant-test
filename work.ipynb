{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Part 1(a): Employee with greater salary than their manager </h1>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "source": [
    "import pandas as pd"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "source": [
    "empl_df = pd.read_csv(\"data/employee_test.csv\")\n",
    "empl_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>salary</th>\n",
       "      <th>manager_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>John</td>\n",
       "      <td>300</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mike</td>\n",
       "      <td>200</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Sally</td>\n",
       "      <td>550</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Jane</td>\n",
       "      <td>500</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Joe</td>\n",
       "      <td>600</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id   name  salary  manager_id\n",
       "0   1   John     300         3.0\n",
       "1   2   Mike     200         3.0\n",
       "2   3  Sally     550         4.0\n",
       "3   4   Jane     500         7.0\n",
       "4   5    Joe     600         7.0"
      ]
     },
     "metadata": {},
     "execution_count": 542
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "source": [
    "def empl_greater_salary(empl_df):\n",
    "    \"\"\"\n",
    "    Retrieve list of employees with salary grater than their manager\n",
    "\n",
    "    Arguments:\n",
    "    empl_df -- employee information, dataframe with 4 columns\n",
    "\n",
    "    Return:\n",
    "    greater_empl_names -- list of employees, list\n",
    "    empl_mgr_df -- employee and their respective manager's information, dataframe with 6 columns \n",
    "    \"\"\"\n",
    "\n",
    "    # Create a new table with both employee and manager information\n",
    "    empl_mgr_df = empl_df.merge(empl_df[['id', 'salary']],\n",
    "                        how='left',\n",
    "                        left_on='manager_id',\n",
    "                        right_on='id',\n",
    "                        suffixes=('_empl', '_mgr'))\n",
    "    \n",
    "    # Apply filter where an employee's salary is larger than their immediate manager\n",
    "    greater_empl_df = empl_mgr_df[empl_mgr_df['salary_empl'] > empl_mgr_df['salary_mgr']]\n",
    "\n",
    "    # Retrieve the names of employees fulfilling the above filter\n",
    "    greater_empl_names = greater_empl_df['name'].to_list()\n",
    "\n",
    "    # Sanity assertions\n",
    "    assert empl_mgr_df.shape[0] == empl_df.shape[0], \"Mismatched in DataFrame sizes.\"\n",
    "\n",
    "    return greater_empl_names, empl_mgr_df\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "source": [
    "greater_empl_names, _ = empl_greater_salary(empl_df)\n",
    "print(\"People with salaries greater than their immediate manager:\", \n",
    "        \", \".join(greater_empl_names))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "People with salaries greater than their immediate manager: Sally, Joe, Dan\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Part 1(b): Average salary of non-managers </h1>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "source": [
    "def non_mgr_salary(empl_df):\n",
    "    \"\"\"\n",
    "    Compute the average salary of non-managers\n",
    "\n",
    "    Arguments:\n",
    "    empl_df -- employee information, dataframe with 4 columns\n",
    "\n",
    "    Return:\n",
    "    avg_non_mgr_salary -- average salary of non-managers, float 2 decimals\n",
    "    non_mgr_df -- information of non-manager employee, dataframe with 4 columns \n",
    "    \"\"\"\n",
    "\n",
    "    # Get a list of employee IDs who are managers\n",
    "    mgr_list = empl_df['manager_id'].dropna().unique()\n",
    "\n",
    "    # Apply filter where employee ID is not in managers list\n",
    "    non_mgr_df = empl_df[~empl_df['id'].isin(mgr_list)]\n",
    "\n",
    "    # Take the average of the non-managers salary\n",
    "    avg_non_mgr_salary = non_mgr_df['salary'].mean()\n",
    "\n",
    "    return round(avg_non_mgr_salary, 2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "source": [
    "avg_non_mgr_salary = non_mgr_salary(empl_df)\n",
    "print(\"Average salary of employees who do not manage anyone:\", avg_non_mgr_salary)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Average salary of employees who do not manage anyone: 425.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1> Part 2: Exists </h1>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def exists(var):\n",
    "    \"\"\"\n",
    "    Check if a variable symbol exists globally\n",
    "\n",
    "    Arguments:\n",
    "    var -- symbol of variable, string\n",
    "\n",
    "    Return:\n",
    "    boolean variable whether var exist in globals\n",
    "    \"\"\"\n",
    "    if type(var) != str:\n",
    "        raise TypeError(\"Input has to be a string.\")\n",
    "    \n",
    "    return var in globals()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "a = 1\n",
    "print(\"Does variable 'a' exist?\", exists('a'))\n",
    "print(\"Does variable 'b' exist?\", exists('b'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Does variable 'a' exist? True\n",
      "Does variable 'b' exist? False\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print(\"Does variable 'a' exist?\", exists(a))"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Input has to be a string.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16812/1064286823.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Does variable 'a' exist?\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16812/1603661831.py\u001b[0m in \u001b[0;36mexists\u001b[1;34m(var)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \"\"\"\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input has to be a string.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Input has to be a string."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Part 3: Pascal triangle</h1>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "For an element $i$ in row $n$ in a Pascal triangle:\n",
    "$$\n",
    "C_{n, i} = \\frac{n!}{i!(n-i)!}\\\\\n",
    "$$\n",
    "\n",
    "To simplify calculation, derive the next term in relation to the previous term:\n",
    "$$\n",
    "C_{n, i+1} = \\frac{n!}{(i+1)!(n-(i+1))!}\\\\\n",
    "C_{n, i+1} = \\frac{n!}{i!(n-i)!}\\frac{(n-i)}{(i+1)}\\\\\n",
    "C_{n, i+1} = C_{n, i}\\frac{(n-i)}{(i+1)}\\\\\n",
    "$$\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "source": [
    "def pascal_row(n):\n",
    "    \"\"\"\n",
    "    Compute the n-th row of the Pascal triangle\n",
    "\n",
    "    Arguments:\n",
    "    n -- row index, integer\n",
    "\n",
    "    Return:\n",
    "    row -- n-th row of the Pascal triangle, list\n",
    "    \"\"\"\n",
    "    if type(n) != int:\n",
    "        raise TypeError(\"Input has to be an integer.\")\n",
    "    elif n < 0:\n",
    "        raise ValueError(\"n cannot be negative.\")\n",
    "\n",
    "    row = [1]\n",
    "    for i in range(n-1):\n",
    "        term = int(row[i]*(n - i)/(i + 1))\n",
    "        row.append(term)\n",
    "\n",
    "    return row"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "source": [
    "row = pascal_row(7)\n",
    "print(\"7-th row of Pascal triangle:\", \" \".join([str(i) for i in row]))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7-th row of Pascal triangle: 1 7 21 35 35 21 7\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Part 4(a): VaR95% and CVaR95% using historical daily returns</h1>\n",
    "\n",
    "Assumptions:\n",
    "- Buy at close on 2016/01/04 (for symmetry)\n",
    "- Daily returns = (prev. day's closing - today's closing)/prev. day's closing\n",
    "- There are no dividends\n",
    "- Trading days are continuous (weekends and off days are ignored)\n",
    "- Stocks are divisible e.g. we can own 0.9 of an AAPL stock\n",
    "- Assume no rebalancing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "source": [
    "# !pip install yfinance\n",
    "import yfinance as yf\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "source": [
    "allocation = {\n",
    "    'AAPL': 0.15,\n",
    "    'IBM': 0.20,\n",
    "    'GOOG': 0.20,\n",
    "    'BP': 0.15,\n",
    "    'XOM': 0.10,\n",
    "    'COST': 0.15,\n",
    "    'GS': 0.05\n",
    "}\n",
    "\n",
    "tickers = list(allocation.keys())\n",
    "weights = np.array(list(allocation.values()))\n",
    "\n",
    "assert weights.sum() == 1, \"Weights do not sum up to 1\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "source": [
    "history = yf.download(tickers, start = '2016-01-01', end = '2016-12-31')\n",
    "history = history[\"Close\"]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[*********************100%***********************]  7 of 7 completed\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "source": [
    "def var_historical(history, weights, alpha):\n",
    "    \"\"\"\n",
    "    Compute historical VaR and CVaR for a given data\n",
    "\n",
    "    Arguments:\n",
    "    history -- historical price data (output from yahoo finance download), dataframe\n",
    "    weights -- list of weights (same ticker order as history columns), np.array\n",
    "    alpha -- level of significance, int\n",
    "\n",
    "    Return:\n",
    "    var -- float\n",
    "    cvar -- float\n",
    "    \"\"\"\n",
    "    if alpha > 1 or alpha < 0:\n",
    "        raise ValueError(\"Alpha must be between 0 and 1\")\n",
    "\n",
    "    # Compute daily returns\n",
    "    daily_returns = history.pct_change()[1:]\n",
    "\n",
    "    # Compute cumulative daily returns\n",
    "    cum_returns = (1 + daily_returns).cumprod()\n",
    "\n",
    "    # Multiply cumulative returns with weights to calculate total portfolio value\n",
    "    pfl_value = (cum_returns * weights).sum(axis=1)\n",
    "                    \n",
    "    # Compute portfolio daily returns                \n",
    "    pfl_returns = pfl_value.pct_change()[1:]\n",
    "\n",
    "    # VaR is equal to the a-th quantile\n",
    "    var = pfl_returns.quantile(alpha)\n",
    "\n",
    "    # CVaR is equal to the mean of returns below VaR\n",
    "    cvar = pfl_returns[pfl_returns <= var].mean()\n",
    "\n",
    "    return var, cvar "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "source": [
    "var95, cvar95 = var_historical(history, weights, alpha=0.05)\n",
    "print(\"Historical VaR95% = {:.2f}%, Historical CVaR95% = {:.2f}%\".format(var95*100, cvar95*100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Historical VaR95% = -1.47%, Historical CVaR95% = -2.22%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Part 4(b): VaR95% and CVaR95% using expected mean, covariance matrix and parametric method</h1>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "source": [
    "from scipy.stats import norm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "source": [
    "def var_parametric(history, weights, alpha):\n",
    "    \"\"\"\n",
    "    Compute VaR and CVaR for a given data using parametric method\n",
    "\n",
    "    Arguments:\n",
    "    history -- historical price data (output from yahoo finance download), dataframe\n",
    "    weights -- list of weights (same ticker order as history columns), np.array\n",
    "    alpha -- level of significance, int\n",
    "\n",
    "    Return:\n",
    "    var -- float\n",
    "    cvar -- float\n",
    "    \"\"\"\n",
    "    if alpha > 1 or alpha < 0:\n",
    "        raise ValueError(\"Alpha must be between 0 and 1\")\n",
    "\n",
    "    # Compute daily returns\n",
    "    daily_returns = history.pct_change()[1:]\n",
    "\n",
    "    # Compute covariance matrix\n",
    "    cov_matrix = daily_returns.cov()\n",
    "\n",
    "    # Compute expected returns for each ticker\n",
    "    avg_returns = daily_returns.mean()\n",
    "\n",
    "    # Compute portfolio daily returns mean and standard deviation\n",
    "    pfl_ret_mean = avg_returns.dot(weights)\n",
    "    pfl_ret_stdev = np.sqrt(weights.T.dot(cov_matrix).dot(weights))\n",
    "\n",
    "    # VaR is equal the a-th percentile assuming normal distribution\n",
    "    var = norm.ppf(alpha)*pfl_ret_stdev + pfl_ret_mean\n",
    "\n",
    "    # CVaR is equal to the expectation of returns below VaR\n",
    "    cvar = pfl_ret_mean - (1/alpha)*norm.pdf(norm.ppf(alpha))*pfl_ret_stdev\n",
    "\n",
    "    return var, cvar"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "source": [
    "var95, cvar95 = var_parametric(history, weights, alpha=0.05)\n",
    "print(\"Parametric VaR95% = {:.2f}%, Parametric CVaR95% = {:.2f}%\".format(var95*100, cvar95*100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parametric VaR95% = -1.49%, Parametric CVaR95% = -1.89%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Part 4(c): Optimal portfolio</h1>\n",
    "\n",
    "Assumptions:\n",
    "- for each month rebalancing, we use all available historical data from 2016/01/01 onwards to optimize portfolio\n",
    "- assume 252 trading days, 21 days a month\n",
    "- optimal portfolio has the highest Sharpe ratio\n",
    "- monthly risk free rate $\\approx$ 0.12%"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "source": [
    "def sim_portfolios(history, n=10000):\n",
    "    \"\"\"\n",
    "    Run a simulation of portfolios with randomized weights\n",
    "\n",
    "    Arguments:\n",
    "    history -- historical price data (output from yahoo finance download), dataframe\n",
    "    n -- number of iterations, integer\n",
    "\n",
    "    Return:\n",
    "    portfolios -- simulation results containing weights, returns and volatility, dataframe\n",
    "    \"\"\"\n",
    "    tickers = list(history.columns)\n",
    "    portfolios = [] # Empty list to store simulation results\n",
    "\n",
    "    # Compute daily returns\n",
    "    daily_returns = history.pct_change()[1:]\n",
    "\n",
    "    # Compute covariance matrix\n",
    "    cov_matrix = daily_returns.cov()\n",
    "\n",
    "    # Compute expected returns for each ticker for 1-month's horizon\n",
    "    avg_returns = history.resample('M').last().pct_change().mean()\n",
    "\n",
    "    # Simulate n portfolios with random weights\n",
    "    for i in range(n):\n",
    "        weights = np.random.uniform(-1, 1, len(tickers)) # Initialize random weights\n",
    "        weights = weights/np.sum(weights) # Normalize weights to a sum of 1\n",
    "\n",
    "        # Re-initialize weights if normalized weights have values bigger than 1\n",
    "        while sum(abs(weights) > 1) > 0:\n",
    "            weights = np.random.uniform(-1, 1, len(tickers))\n",
    "            weights = weights/np.sum(weights)\n",
    "\n",
    "        returns = avg_returns.dot(weights) # Compute expected portfolio returns\n",
    "        \n",
    "        # Compute daily volatility\n",
    "        volatility = np.sqrt(weights.T.dot(cov_matrix).dot(weights))*np.sqrt(21)\n",
    "\n",
    "        # Store result in list\n",
    "        portfolios.append(weights.tolist() + [returns, volatility])\n",
    "\n",
    "    # Store results in a dataframe\n",
    "    portfolios = pd.DataFrame(portfolios)\n",
    "    portfolios.columns = tickers + [\"Returns\", \"Volatility\"]\n",
    "\n",
    "    return portfolios"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "source": [
    "def monthly_rebalance(history, n=10000, rf=0.0012):\n",
    "    \"\"\"\n",
    "    Rebalance portfolio at the end of every month using simulation\n",
    "\n",
    "    Arguments:\n",
    "    history -- historical price data (output from yahoo finance download), dataframe\n",
    "    n -- number of iterations, integer\n",
    "\n",
    "    Return:\n",
    "    weights -- rebalanced weights at the end of every month, dataframe\n",
    "    \"\"\"\n",
    "    tickers = list(history.columns)\n",
    "\n",
    "    # Get a list of end-of-month dates\n",
    "    eom = history.resample('M').last()\n",
    "\n",
    "    weights = [] # Empty list to store optimal portfolio allocation\n",
    "\n",
    "    for date in eom.index[1:]:\n",
    "        # Run a simulation\n",
    "        portfolios = sim_portfolios(history[:date], n=n)\n",
    "\n",
    "        # Get the index of the portfolio with the highest Sharpe ratio\n",
    "        optimal_pfl_index = ((portfolios['Returns'] - rf)/portfolios['Volatility']).idxmax()\n",
    "\n",
    "        # Get the weights, returns and volatility details of the optimal portfolio\n",
    "        optimal_pfl = portfolios.iloc[optimal_pfl_index]\n",
    "\n",
    "        # Add optimal portfolio details in weights\n",
    "        weights.append(optimal_pfl[:len(tickers)].to_list())\n",
    "\n",
    "    # Store optimal portfolio details in a dataframe\n",
    "    weights = pd.DataFrame(weights, index=eom.index[1:])\n",
    "    weights.columns = tickers\n",
    "\n",
    "    return weights\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "source": [
    "monthly_weights = monthly_rebalance(history, n=20000)\n",
    "print(\"Optimal portfolio holding by end of each month:\")\n",
    "monthly_weights"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Optimal portfolio holding by end of each month:\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>BP</th>\n",
       "      <th>COST</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>GS</th>\n",
       "      <th>IBM</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-31</th>\n",
       "      <td>-0.731696</td>\n",
       "      <td>0.617261</td>\n",
       "      <td>0.804817</td>\n",
       "      <td>0.988144</td>\n",
       "      <td>-0.939591</td>\n",
       "      <td>-0.694324</td>\n",
       "      <td>0.955389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-02-29</th>\n",
       "      <td>-0.030336</td>\n",
       "      <td>-0.033153</td>\n",
       "      <td>0.338521</td>\n",
       "      <td>0.234500</td>\n",
       "      <td>-0.952462</td>\n",
       "      <td>0.567769</td>\n",
       "      <td>0.875160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-03-31</th>\n",
       "      <td>0.728207</td>\n",
       "      <td>-0.115636</td>\n",
       "      <td>-0.096833</td>\n",
       "      <td>0.224056</td>\n",
       "      <td>-0.906948</td>\n",
       "      <td>0.655058</td>\n",
       "      <td>0.512097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-04-30</th>\n",
       "      <td>-0.343541</td>\n",
       "      <td>0.334267</td>\n",
       "      <td>-0.479381</td>\n",
       "      <td>0.304368</td>\n",
       "      <td>-0.659971</td>\n",
       "      <td>0.863059</td>\n",
       "      <td>0.981199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-31</th>\n",
       "      <td>0.227765</td>\n",
       "      <td>-0.132469</td>\n",
       "      <td>-0.712277</td>\n",
       "      <td>0.298611</td>\n",
       "      <td>-0.547678</td>\n",
       "      <td>0.921657</td>\n",
       "      <td>0.944390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-06-30</th>\n",
       "      <td>-0.268249</td>\n",
       "      <td>0.100674</td>\n",
       "      <td>0.401692</td>\n",
       "      <td>-0.134416</td>\n",
       "      <td>-0.735404</td>\n",
       "      <td>0.835611</td>\n",
       "      <td>0.800093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-07-31</th>\n",
       "      <td>-0.002402</td>\n",
       "      <td>0.055831</td>\n",
       "      <td>0.352883</td>\n",
       "      <td>-0.159491</td>\n",
       "      <td>-0.792956</td>\n",
       "      <td>0.660557</td>\n",
       "      <td>0.885578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-08-31</th>\n",
       "      <td>0.142986</td>\n",
       "      <td>-0.115834</td>\n",
       "      <td>-0.136485</td>\n",
       "      <td>0.151237</td>\n",
       "      <td>-0.734933</td>\n",
       "      <td>0.879631</td>\n",
       "      <td>0.813397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-30</th>\n",
       "      <td>0.622206</td>\n",
       "      <td>0.167668</td>\n",
       "      <td>-0.357772</td>\n",
       "      <td>0.320852</td>\n",
       "      <td>-0.787890</td>\n",
       "      <td>0.775755</td>\n",
       "      <td>0.259181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-10-31</th>\n",
       "      <td>0.579469</td>\n",
       "      <td>0.430454</td>\n",
       "      <td>-0.826571</td>\n",
       "      <td>0.632487</td>\n",
       "      <td>-0.894781</td>\n",
       "      <td>0.787931</td>\n",
       "      <td>0.291011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-11-30</th>\n",
       "      <td>0.453397</td>\n",
       "      <td>-0.479747</td>\n",
       "      <td>-0.843062</td>\n",
       "      <td>-0.398963</td>\n",
       "      <td>0.820828</td>\n",
       "      <td>0.773042</td>\n",
       "      <td>0.674504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>0.182036</td>\n",
       "      <td>-0.241794</td>\n",
       "      <td>-0.078302</td>\n",
       "      <td>-0.370168</td>\n",
       "      <td>0.660573</td>\n",
       "      <td>0.564229</td>\n",
       "      <td>0.283425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AAPL        BP      COST      GOOG        GS       IBM  \\\n",
       "Date                                                                     \n",
       "2016-01-31 -0.731696  0.617261  0.804817  0.988144 -0.939591 -0.694324   \n",
       "2016-02-29 -0.030336 -0.033153  0.338521  0.234500 -0.952462  0.567769   \n",
       "2016-03-31  0.728207 -0.115636 -0.096833  0.224056 -0.906948  0.655058   \n",
       "2016-04-30 -0.343541  0.334267 -0.479381  0.304368 -0.659971  0.863059   \n",
       "2016-05-31  0.227765 -0.132469 -0.712277  0.298611 -0.547678  0.921657   \n",
       "2016-06-30 -0.268249  0.100674  0.401692 -0.134416 -0.735404  0.835611   \n",
       "2016-07-31 -0.002402  0.055831  0.352883 -0.159491 -0.792956  0.660557   \n",
       "2016-08-31  0.142986 -0.115834 -0.136485  0.151237 -0.734933  0.879631   \n",
       "2016-09-30  0.622206  0.167668 -0.357772  0.320852 -0.787890  0.775755   \n",
       "2016-10-31  0.579469  0.430454 -0.826571  0.632487 -0.894781  0.787931   \n",
       "2016-11-30  0.453397 -0.479747 -0.843062 -0.398963  0.820828  0.773042   \n",
       "2016-12-31  0.182036 -0.241794 -0.078302 -0.370168  0.660573  0.564229   \n",
       "\n",
       "                 XOM  \n",
       "Date                  \n",
       "2016-01-31  0.955389  \n",
       "2016-02-29  0.875160  \n",
       "2016-03-31  0.512097  \n",
       "2016-04-30  0.981199  \n",
       "2016-05-31  0.944390  \n",
       "2016-06-30  0.800093  \n",
       "2016-07-31  0.885578  \n",
       "2016-08-31  0.813397  \n",
       "2016-09-30  0.259181  \n",
       "2016-10-31  0.291011  \n",
       "2016-11-30  0.674504  \n",
       "2016-12-31  0.283425  "
      ]
     },
     "metadata": {},
     "execution_count": 557
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Part 5(a): Count of Python Files</h1>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h1>Part 6: Count Dates</h1>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "source": [
    "import re\n",
    "import dateutil"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "source": [
    "# Formats for date parts\n",
    "DAY = \"\\d{2}\" # Capture any 2 digits number\n",
    "MONTH = \"\\d{2}\" # Capture any 2 digits number \n",
    "MONTHSTR = \"Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sept|Oct|Nov|Dec\" # Capture abbreviated months\n",
    "YEAR = \"\\d{4}\" # Capture any 4 digits number \n",
    "\n",
    "DATE_PATTERNS = r\"\"\"\n",
    "    (?:{year})/(?:{month})/(?:{day}) | # Capture YYYY/MM/DD format\n",
    "    (?:{month})/(?:{day})/(?:{year}) | # Capture MM/DD/YYYY format\n",
    "    (?:{day})/(?:{month})/(?:{year}) | # Capture DD/MM/YYYY format\n",
    "    (?:{day})[ ](?:{monthstr})[ ](?:{year}) # Capture DD MMM YYYY format\n",
    "\"\"\"\n",
    "\n",
    "DATE_PATTERNS = DATE_PATTERNS.format(\n",
    "    day=DAY,\n",
    "    month=MONTH,\n",
    "    monthstr=MONTHSTR,\n",
    "    year=YEAR\n",
    ")\n",
    "\n",
    "DATE_REGEX = re.compile(DATE_PATTERNS, re.VERBOSE) # Compile with verbose"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "source": [
    "def count_dates(text):\n",
    "    \"\"\"\n",
    "    Count the number of date occurences in a text\n",
    "\n",
    "    Arguments:\n",
    "    text -- string\n",
    "\n",
    "    Return:\n",
    "    count -- number of date occurences, integer\n",
    "    \"\"\"\n",
    "    # Initiate count to zero\n",
    "    count = 0\n",
    "    \n",
    "    # Loop through all potential matches\n",
    "    for val in DATE_REGEX.findall(text):\n",
    "        try: \n",
    "             # Pass through potential match into a built-in date parse to check validity\n",
    "            dateutil.parser.parse(val)\n",
    "            count += 1\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    return count"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "source": [
    "with open('data/date_text.txt') as f:\n",
    "    text = f.read()\n",
    "\n",
    "count = count_dates(text)\n",
    "print(\"Number of date occurences: \", count)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of date occurences:  8\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.0",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "interpreter": {
   "hash": "f072f515e3c5553065c9df26789aad47a13957d7deed1f83531f1ed6793a3a60"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}